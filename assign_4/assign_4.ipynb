{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODtdHyQGiKMAGMgO6Mihcb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gc2321/3546-Deep-Learning/blob/main/assign_4/assign_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "shapes3d: https://www.tensorflow.org/datasets/catalog/shapes3d"
      ],
      "metadata": {
        "id": "zdUrxuHAz87O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "Praz63WE0p8L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "tq_F4Kp72i_K"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = tfds.builder('shapes3d').info"
      ],
      "metadata": {
        "id": "Tws-qVes2lW6"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l30YSupM2yeM",
        "outputId": "3f0a7e6c-f583-4d02-d151-85e96c1a805d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='shapes3d',\n",
              "    full_name='shapes3d/2.0.0',\n",
              "    description=\"\"\"\n",
              "    3dshapes is a dataset of 3D shapes procedurally generated from 6 ground truth\n",
              "    independent latent factors. These factors are *floor colour*, *wall colour*,\n",
              "    *object colour*, *scale*, *shape* and *orientation*.\n",
              "    \n",
              "    All possible combinations of these latents are present exactly once, generating\n",
              "    N = 480000 total images.\n",
              "    \n",
              "    ### Latent factor values\n",
              "    \n",
              "    *   floor hue: 10 values linearly spaced in [0, 1]\n",
              "    *   wall hue: 10 values linearly spaced in [0, 1]\n",
              "    *   object hue: 10 values linearly spaced in [0, 1]\n",
              "    *   scale: 8 values linearly spaced in [0, 1]\n",
              "    *   shape: 4 values in [0, 1, 2, 3]\n",
              "    *   orientation: 15 values linearly spaced in [-30, 30]\n",
              "    \n",
              "    We varied one latent at a time (starting from orientation, then shape, etc), and\n",
              "    sequentially stored the images in fixed order in the `images` array. The\n",
              "    corresponding values of the factors are stored in the same order in the `labels`\n",
              "    array.\n",
              "    \"\"\",\n",
              "    homepage='https://github.com/deepmind/3d-shapes',\n",
              "    data_dir='/root/tensorflow_datasets/shapes3d/2.0.0',\n",
              "    file_format=tfrecord,\n",
              "    download_size=255.18 MiB,\n",
              "    dataset_size=1.68 GiB,\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(64, 64, 3), dtype=uint8),\n",
              "        'label_floor_hue': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
              "        'label_object_hue': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
              "        'label_orientation': ClassLabel(shape=(), dtype=int64, num_classes=15),\n",
              "        'label_scale': ClassLabel(shape=(), dtype=int64, num_classes=8),\n",
              "        'label_shape': ClassLabel(shape=(), dtype=int64, num_classes=4),\n",
              "        'label_wall_hue': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
              "        'value_floor_hue': float32,\n",
              "        'value_object_hue': float32,\n",
              "        'value_orientation': float32,\n",
              "        'value_scale': float32,\n",
              "        'value_shape': float32,\n",
              "        'value_wall_hue': float32,\n",
              "    }),\n",
              "    supervised_keys=None,\n",
              "    disable_shuffling=False,\n",
              "    splits={\n",
              "        'train': <SplitInfo num_examples=480000, num_shards=16>,\n",
              "    },\n",
              "    citation=\"\"\"@misc{3dshapes18,\n",
              "      title={3D Shapes Dataset},\n",
              "      author={Burgess, Chris and Kim, Hyunjik},\n",
              "      howpublished={https://github.com/deepmind/3dshapes-dataset/},\n",
              "      year={2018}\n",
              "    }\"\"\",\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = info.splits['train'].num_examples\n",
        "# take 30% of data\n",
        "take_data = int(0.3 * total)\n",
        "train_dataset = tfds.load('shapes3d', split=f'train[:{take_data}]')"
      ],
      "metadata": {
        "id": "OIUwH1Jl22R_"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "take_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuY5OKY722OF",
        "outputId": "eb641789-d9c4-40e4-a53f-3432217315bb"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144000"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "    image = tf.cast(data['image'], tf.float32) / 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "gzY-hjU122GN"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(preprocess_data)\n",
        "train_dataset = train_dataset.batch(batch_size=32, drop_remainder=True)\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "px_gkeh776nI"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variational Autoencoder"
      ],
      "metadata": {
        "id": "ENKf4e2f0bcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/tutorials/generative/cvae#network_architecture\n",
        "\n",
        "class CVAE(tf.keras.Model):\n",
        "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim):\n",
        "        \"\"\"\n",
        "        latent_dim: int, typically much smaller than the original input dimension and represent the compressed, encoded version of the data.\n",
        "        \"\"\"\n",
        "        super(CVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape=(64, 64, 3)),\n",
        "                # 4 layers\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=32, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
        "                ),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
        "                ),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=128, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
        "                ),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=256, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
        "                ),\n",
        "                tf.keras.layers.Flatten(),\n",
        "                # No activation\n",
        "                tf.keras.layers.Dense(latent_dim + latent_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.decoder = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "                tf.keras.layers.Dense(units=4 * 4 * 256, activation=tf.nn.relu),\n",
        "                tf.keras.layers.Reshape(target_shape=(4, 4, 256)),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=128,\n",
        "                    kernel_size=3,\n",
        "                    strides=2,\n",
        "                    padding=\"same\",\n",
        "                    activation=\"relu\",\n",
        "                ),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=64,\n",
        "                    kernel_size=3,\n",
        "                    strides=2,\n",
        "                    padding=\"same\",\n",
        "                    activation=\"relu\",\n",
        "                ),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=32,\n",
        "                    kernel_size=3,\n",
        "                    strides=2,\n",
        "                    padding=\"same\",\n",
        "                    activation=\"relu\",\n",
        "                ),\n",
        "                # No activation\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=3, kernel_size=3, strides=2, padding=\"same\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def encode(self, x):\n",
        "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        batch_size = tf.shape(mean)[0]  # Get batch size dynamically\n",
        "        eps = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        return eps * tf.exp(logvar * 0.5) + mean\n",
        "\n",
        "    def decode(self, z, apply_sigmoid=False):\n",
        "        logits = self.decoder(z)\n",
        "        if apply_sigmoid:\n",
        "            probs = tf.sigmoid(logits)\n",
        "            return probs\n",
        "        return logits\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        images, _ = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            mean, logvar = self.encode(images)\n",
        "            z = self.reparameterize(mean, logvar)\n",
        "            reconstruction = self.decode(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    tf.keras.losses.binary_crossentropy(images, reconstruction),\n",
        "                    axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * tf.reduce_mean(\n",
        "                tf.reduce_sum(1 + logvar - tf.square(mean) - tf.exp(logvar), axis=1)\n",
        "            )\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "Y_djd1WqED-q"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "OMCN68lV_vyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aSDz-GvvFcsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2\n",
        "cvae = CVAE(latent_dim)\n",
        "cvae.compile(optimizer=tf.keras.optimizers.Adam())"
      ],
      "metadata": {
        "id": "qtHUeBLXA62B"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvae.fit(train_dataset, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "ypXG_MTxDR7-",
        "outputId": "9db41652-2005-41d6-ff0b-fd2893727365"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OperatorNotAllowedInGraphError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"<ipython-input-91-a7a0c0d0bb15>\", line 99, in train_step  *\n        images, _ = data\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-f2338f5e28f2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"<ipython-input-91-a7a0c0d0bb15>\", line 99, in train_step  *\n        images, _ = data\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cbpyt019DXPx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}