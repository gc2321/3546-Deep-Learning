{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMfDG3T5Ya0YsmwQfk24QQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gc2321/3546-Deep-Learning/blob/main/assign_4/assign_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "shapes3d: https://www.tensorflow.org/datasets/catalog/shapes3d"
      ],
      "metadata": {
        "id": "zdUrxuHAz87O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "Praz63WE0p8L"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "tq_F4Kp72i_K"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = tfds.builder('shapes3d').info"
      ],
      "metadata": {
        "id": "Tws-qVes2lW6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#info"
      ],
      "metadata": {
        "id": "l30YSupM2yeM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = info.splits['train'].num_examples\n",
        "# take 30% of data\n",
        "take_data = int(0.3 * total)\n",
        "train_dataset = tfds.load('shapes3d', split=f'train[:{take_data}]')"
      ],
      "metadata": {
        "id": "OIUwH1Jl22R_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "take_data"
      ],
      "metadata": {
        "id": "PuY5OKY722OF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec4a76c1-364a-4d15-a3b0-d770352b451f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144000"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "    image = tf.cast(data['image'], tf.float32) / 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "gzY-hjU122GN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(preprocess_data)\n",
        "train_dataset = train_dataset.batch(batch_size=32)\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "px_gkeh776nI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variational Autoencoder"
      ],
      "metadata": {
        "id": "ENKf4e2f0bcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/tutorials/generative/cvae#network_architecture\n",
        "\n",
        "class CVAE(tf.keras.Model):\n",
        "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim=2):\n",
        "        \"\"\"\n",
        "        latent_dim: int, typically much smaller than the original input dimension and represent the compressed, encoded version of the data.\n",
        "        \"\"\"\n",
        "        super(CVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape=(64, 64, 3)),\n",
        "                # 4 layers\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=32, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
        "                ),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
        "                ),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
        "                ),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
        "                ),\n",
        "                tf.keras.layers.Flatten(),\n",
        "                # No activation\n",
        "                tf.keras.layers.Dense(latent_dim + latent_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.decoder = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "                tf.keras.layers.Dense(units=8 * 8 * 32, activation=tf.nn.relu),\n",
        "                tf.keras.layers.Reshape(target_shape=(8, 8, 32)),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=64,\n",
        "                    kernel_size=3,\n",
        "                    strides=2,\n",
        "                    padding=\"same\",\n",
        "                    activation=\"relu\",\n",
        "                ),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=32,\n",
        "                    kernel_size=3,\n",
        "                    strides=2,\n",
        "                    padding=\"same\",\n",
        "                    activation=\"relu\",\n",
        "                ),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=64,\n",
        "                    kernel_size=3,\n",
        "                    strides=2,\n",
        "                    padding=\"same\",\n",
        "                    activation=\"relu\",\n",
        "                ),\n",
        "                # No activation\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=3, kernel_size=3, strides=1, padding=\"same\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    def encode(self, x):\n",
        "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        eps = tf.random.normal(shape=tf.shape(mean))\n",
        "        return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "    def decode(self, z, apply_sigmoid=False):\n",
        "        logits = self.decoder(z)\n",
        "        if apply_sigmoid:\n",
        "            probs = tf.sigmoid(logits)\n",
        "            return probs\n",
        "        return logits\n",
        "\n",
        "    @tf.function\n",
        "    def sample(self, z=None):\n",
        "        if z is None:\n",
        "            z = tf.random.normal(shape=(100, self.latent_dim))\n",
        "        return self.decode(z, apply_sigmoid=True)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Access the images using indexing\n",
        "        images = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            mean, logvar = self.encode(images)\n",
        "            z = self.reparameterize(mean, logvar)\n",
        "            reconstruction = self.decode(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    tf.keras.losses.binary_crossentropy(images, reconstruction),\n",
        "                    axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * tf.reduce_mean(\n",
        "                tf.reduce_sum(1 + logvar - tf.square(mean) - tf.exp(logvar), axis=1)\n",
        "            )\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "Y_djd1WqED-q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "OMCN68lV_vyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cvae = CVAE()\n",
        "cvae.compile(optimizer=tf.keras.optimizers.Adam())"
      ],
      "metadata": {
        "id": "qtHUeBLXA62B"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvae.fit(train_dataset, epochs=15)"
      ],
      "metadata": {
        "id": "ypXG_MTxDR7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447b6f60-9917-46be-d005-478d1c0ed45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4500/4500 [==============================] - 1498s 332ms/step - loss: 2466.9169 - reconstruction_loss: 1992.6205 - kl_loss: 8.2810\n",
            "Epoch 2/20\n",
            "4500/4500 [==============================] - 1486s 330ms/step - loss: 1599.5425 - reconstruction_loss: 1576.1165 - kl_loss: 8.5997\n",
            "Epoch 3/20\n",
            "4500/4500 [==============================] - 1471s 327ms/step - loss: 1559.5693 - reconstruction_loss: 1555.1710 - kl_loss: 8.4914\n",
            "Epoch 4/20\n",
            "4500/4500 [==============================] - 1467s 326ms/step - loss: 1545.1163 - reconstruction_loss: 1540.2892 - kl_loss: 8.4356\n",
            "Epoch 5/20\n",
            "4500/4500 [==============================] - 1458s 324ms/step - loss: 1536.9483 - reconstruction_loss: 1531.0983 - kl_loss: 8.5616\n",
            "Epoch 6/20\n",
            "4500/4500 [==============================] - 1452s 323ms/step - loss: 1531.9615 - reconstruction_loss: 1525.0701 - kl_loss: 8.6051\n",
            "Epoch 7/20\n",
            "4500/4500 [==============================] - 1446s 321ms/step - loss: 1528.4303 - reconstruction_loss: 1520.8304 - kl_loss: 8.7120\n",
            "Epoch 8/20\n",
            "4500/4500 [==============================] - 1440s 320ms/step - loss: 1512.1602 - reconstruction_loss: 1503.8459 - kl_loss: 8.9566\n",
            "Epoch 9/20\n",
            "4500/4500 [==============================] - 1487s 330ms/step - loss: 1518.7563 - reconstruction_loss: 1497.6243 - kl_loss: 9.0893\n",
            "Epoch 10/20\n",
            "4500/4500 [==============================] - 1443s 321ms/step - loss: 1497.0529 - reconstruction_loss: 1490.0951 - kl_loss: 9.2180\n",
            "Epoch 11/20\n",
            "4500/4500 [==============================] - 1439s 320ms/step - loss: 1490.3084 - reconstruction_loss: 1476.0183 - kl_loss: 9.3785\n",
            "Epoch 12/20\n",
            "4500/4500 [==============================] - 1441s 320ms/step - loss: 1486.7471 - reconstruction_loss: 1479.8496 - kl_loss: 9.4447\n",
            "Epoch 13/20\n",
            "4500/4500 [==============================] - 1441s 320ms/step - loss: 1481.9949 - reconstruction_loss: 1471.6630 - kl_loss: 9.5835\n",
            "Epoch 14/20\n",
            "4500/4500 [==============================] - 1439s 320ms/step - loss: 1472.6311 - reconstruction_loss: 1461.5471 - kl_loss: 9.7754\n",
            "Epoch 15/20\n",
            "4500/4500 [==============================] - 1437s 319ms/step - loss: 1503.0442 - reconstruction_loss: 1488.3319 - kl_loss: 9.6675\n",
            "Epoch 16/20\n",
            "4500/4500 [==============================] - 1458s 324ms/step - loss: 1468.4132 - reconstruction_loss: 1461.7643 - kl_loss: 9.8499\n",
            "Epoch 17/20\n",
            "3618/4500 [=======================>......] - ETA: 4:42 - loss: 1489.2483 - reconstruction_loss: 1477.2993 - kl_loss: 9.7783"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show 2D manifolds of the code"
      ],
      "metadata": {
        "id": "8i2i9zgzSs23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp"
      ],
      "metadata": {
        "id": "fU6c93C0gidr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_latent_images(model, n, digit_size=64):\n",
        "    norm = tfp.distributions.Normal(0, 1)\n",
        "    grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
        "    grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
        "    image_width = digit_size * n\n",
        "    image_height = image_width\n",
        "    image = np.zeros((image_height, image_width, 3))\n",
        "\n",
        "    for i, yi in enumerate(grid_x):\n",
        "        for j, xi in enumerate(grid_y):\n",
        "            z = np.array([[xi, yi]])\n",
        "            x_decoded = model.sample(z)\n",
        "            digit_rgb = tf.image.resize(x_decoded[0], (digit_size, digit_size))\n",
        "            digit_rgb = tf.clip_by_value(digit_rgb, 0.0, 1.0)\n",
        "            image[i * digit_size: (i + 1) * digit_size,\n",
        "                  j * digit_size: (j + 1) * digit_size] = digit_rgb.numpy()\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('Off')\n",
        "    plt.show()\n",
        "\n",
        "plot_latent_images(cvae, 10)"
      ],
      "metadata": {
        "id": "LgZjYMzGETc5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}