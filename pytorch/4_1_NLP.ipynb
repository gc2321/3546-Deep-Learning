{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPruYZSzjUb2FF9q+f7m00w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gc2321/3546-Deep-Learning/blob/main/pytorch/4_1_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OziT1vTBlMfo"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "3BIipZed53pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"/content/gdrive/MyDrive/neural_data/shakespeare.txt\""
      ],
      "metadata": {
        "id": "CAHjcbSdNzj9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gV230DmPeIB",
        "outputId": "631cc612-7359-4b3a-fc61-c826371d81b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file,'r',encoding='utf8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "GamoGy3xPh2s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "x_-1qOzfP6sk",
        "outputId": "f5e80eeb-2a91-4e7d-abad-b5b3e41a2fcb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bud buriest thy content,\\n  And tender churl mak'st waste in niggarding:\\n    Pity the world, or else this glutton be,\\n    To eat the world's due, by the grave and thee.\\n\\n\\n                     2\\n  When forty winters shall besiege thy brow,\\n  And dig deep trenches in thy beauty's field,\\n  Thy youth's proud livery so gazed on now,\\n  Will be a tattered weed of small worth held:  \\n  Then being asked, where all thy beauty lies,\\n  Where all the treasure of thy lusty days;\\n  To say within thine own deep su\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqNNs6PiPvY9",
        "outputId": "442bc5d9-f990-4ab9-a17d-e84b6b27ed91"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bud buriest thy content,\n",
            "  And tender churl mak'st waste in niggarding:\n",
            "    Pity the world, or else this glutton be,\n",
            "    To eat the world's due, by the grave and thee.\n",
            "\n",
            "\n",
            "                     2\n",
            "  When forty winters shall besiege thy brow,\n",
            "  And dig deep trenches in thy beauty's field,\n",
            "  Thy youth's proud livery so gazed on now,\n",
            "  Will be a tattered weed of small worth held:  \n",
            "  Then being asked, where all thy beauty lies,\n",
            "  Where all the treasure of thy lusty days;\n",
            "  To say within thine own deep su\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "id": "wjAjXOQIqC6x",
        "outputId": "562298ac-f1fb-4471-f8b3-1539e8785591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5445609"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode Entire Text"
      ],
      "metadata": {
        "id": "iOBi3M-SqGw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = set(text)"
      ],
      "metadata": {
        "id": "M36b31GlqFBr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters"
      ],
      "metadata": {
        "id": "rDnKBF0vqKze",
        "outputId": "e715201b-281e-4ff6-93e5-14c53ff6ed22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '>',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '|',\n",
              " '}'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = dict(enumerate(all_characters))"
      ],
      "metadata": {
        "id": "GwSY9J7sqNvm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = {char: ind for ind,char in decoder.items()}"
      ],
      "metadata": {
        "id": "SS6OKcMmqQnM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = np.array([encoder[char] for char in text])"
      ],
      "metadata": {
        "id": "CFmy_-4fqS5E"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text[:500]"
      ],
      "metadata": {
        "id": "Xkyq2H4uqYpg",
        "outputId": "7dc65cfc-f432-4ac5-bd05-18f5423650f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([49, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
              "       64, 64, 64, 64, 64, 46, 49, 64, 64, 34, 69, 21, 50, 64,  5, 31, 71,\n",
              "       69, 40, 78, 51, 64, 61, 69, 40, 31, 51, 19, 69, 40, 78, 64, 13, 40,\n",
              "       64, 25, 40, 78, 71, 69, 40, 64, 71, 74, 61, 69, 40, 31, 78, 40, 30,\n",
              "       49, 64, 64, 42, 60, 31, 51, 64, 51, 60, 40, 69, 40,  7, 58, 64,  7,\n",
              "       40, 31, 19, 51, 58,  6, 78, 64, 69, 21, 78, 40, 64, 50, 71, 62, 60,\n",
              "       51, 64, 74, 40, 41, 40, 69, 64, 25, 71, 40, 30, 49, 64, 64, 73, 19,\n",
              "       51, 64, 31, 78, 64, 51, 60, 40, 64, 69, 71, 43, 40, 69, 64, 78, 60,\n",
              "       21, 19, 10, 25, 64,  7, 58, 64, 51, 71, 50, 40, 64, 25, 40, 61, 40,\n",
              "       31, 78, 40, 30, 49, 64, 64, 80, 71, 78, 64, 51, 40, 74, 25, 40, 69,\n",
              "       64, 60, 40, 71, 69, 64, 50, 71, 62, 60, 51, 64,  7, 40, 31, 69, 64,\n",
              "       60, 71, 78, 64, 50, 40, 50, 21, 69, 58,  0, 49, 64, 64, 73, 19, 51,\n",
              "       64, 51, 60, 21, 19, 64, 61, 21, 74, 51, 69, 31, 61, 51, 40, 25, 64,\n",
              "       51, 21, 64, 51, 60, 71, 74, 40, 64, 21, 13, 74, 64,  7, 69, 71, 62,\n",
              "       60, 51, 64, 40, 58, 40, 78, 30, 49, 64, 64, 34, 40, 40, 25,  6, 78,\n",
              "       51, 64, 51, 60, 58, 64, 10, 71, 62, 60, 51,  6, 78, 64,  5, 10, 31,\n",
              "       50, 40, 64, 13, 71, 51, 60, 64, 78, 40, 10,  5, 18, 78, 19,  7, 78,\n",
              "       51, 31, 74, 51, 71, 31, 10, 64,  5, 19, 40, 10, 30, 49, 64, 64,  8,\n",
              "       31, 68, 71, 74, 62, 64, 31, 64,  5, 31, 50, 71, 74, 40, 64, 13, 60,\n",
              "       40, 69, 40, 64, 31,  7, 19, 74, 25, 31, 74, 61, 40, 64, 10, 71, 40,\n",
              "       78, 30, 49, 64, 64, 42, 60, 58, 64, 78, 40, 10,  5, 64, 51, 60, 58,\n",
              "       64,  5, 21, 40, 30, 64, 51, 21, 64, 51, 60, 58, 64, 78, 13, 40, 40,\n",
              "       51, 64, 78, 40, 10,  5, 64, 51, 21, 21, 64, 61, 69, 19, 40, 10,  0,\n",
              "       49, 64, 64, 42, 60, 21, 19, 64, 51, 60, 31, 51, 64, 31, 69, 51, 64,\n",
              "       74, 21, 13, 64, 51, 60, 40, 64, 13, 21, 69, 10, 25,  6, 78, 64,  5,\n",
              "       69, 40, 78, 60, 64, 21, 69, 74, 31, 50, 40, 74, 51, 30, 49, 64, 64,\n",
              "        4, 74, 25, 64, 21, 74, 10, 58, 64, 60, 40, 69, 31, 10, 25, 64, 51,\n",
              "       21, 64, 51, 60, 40, 64, 62, 31, 19, 25, 58, 64, 78, 43, 69, 71, 74,\n",
              "       62, 30, 49, 64, 64, 37, 71, 51, 60, 71, 74, 64, 51, 60, 71, 74, 40,\n",
              "       64, 21, 13, 74, 64,  7, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding"
      ],
      "metadata": {
        "id": "ep9R8PfJrcS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoder(encoded_text, num_uni_chars):\n",
        "    '''\n",
        "    encoded_text : batch of encoded text\n",
        "\n",
        "    num_uni_chars = number of unique characters (len(set(text)))\n",
        "    '''\n",
        "\n",
        "    # METHOD FROM:\n",
        "    # https://stackoverflow.com/questions/29831489/convert-encoded_textay-of-indices-to-1-hot-encoded-numpy-encoded_textay\n",
        "\n",
        "    # Create a placeholder for zeros.\n",
        "    one_hot = np.zeros((encoded_text.size, num_uni_chars))\n",
        "\n",
        "    # Convert data type for later use with pytorch (errors if we dont!)\n",
        "    one_hot = one_hot.astype(np.float32)\n",
        "\n",
        "    # Using fancy indexing fill in the 1s at the correct index locations\n",
        "    one_hot[np.arange(one_hot.shape[0]), encoded_text.flatten()] = 1.0\n",
        "\n",
        "\n",
        "    # Reshape it so it matches the batch sahe\n",
        "    one_hot = one_hot.reshape((*encoded_text.shape, num_uni_chars))\n",
        "\n",
        "    return one_hot"
      ],
      "metadata": {
        "id": "UKwrc60Lqbkz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder(np.array([1,2,0]),3)"
      ],
      "metadata": {
        "id": "5R31BPAurg6O",
        "outputId": "a0877be6-262a-480c-87e5-999db2dd5225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QlioyFYWt3Ac"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}